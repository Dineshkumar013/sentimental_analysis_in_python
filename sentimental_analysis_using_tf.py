# -*- coding: utf-8 -*-
"""sentimental analysis using tf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11oEm5UVUrs-uFPq4wki97Iz5n3bhIQW4
"""

import pandas as pd
df= pd.read_csv('/content/Tweets.csv', sep=',')
df.head(10)

#select relavant columns
tweet_df = df[['text','airline_sentiment']]

tweet_df = tweet_df[tweet_df['airline_sentiment'] != 'neutral']

# convert airline_seentiment to numeric
sentiment_label = tweet_df.airline_sentiment.factorize()

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
tweet = tweet_df.text.values
tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(tweet)
vocab_size = len(tokenizer.word_index) + 1
encoded_docs = tokenizer.texts_to_sequences(tweet)
padded_sequence = pad_sequences( encoded_docs,padding="pre",maxlen=200)

print(tokenizer.word_index)

print(tweet[30])
print(encoded_docs[30])

print(padded_sequence[30])

# Build the model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM,Dense, Dropout
from tensorflow.keras.layers import SpatialDropout1D
from tensorflow.keras.layers import Embedding
embedding_vector_length = 32
model = Sequential()
model.add(Embedding(vocab_size, embedding_vector_length,     
                                     input_length=200) )
model.add(SpatialDropout1D(0.25))
model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))
model.add(Dropout(0.2))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy',optimizer='adam', 
                           metrics=['accuracy'])
print(model.summary())

history = model.fit(padded_sequence,sentiment_label[0],
                  validation_split=0.2, epochs=5, batch_size=32)

test_word ="This is so BAD"
tw = tokenizer.texts_to_sequences([test_word])
tw = pad_sequences(tw,maxlen=200)
prediction = int(model.predict(tw).round().item())
sentiment_label[1][prediction]